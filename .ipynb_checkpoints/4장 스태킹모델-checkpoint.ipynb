{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 스태킹 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스태킹에 사용될 머신러닝 알고리즘 클래스를 생성합니다.\n",
    "<br> 개별 모델은 KNN, 랜덤 포레스트, 결정 트리, 에이다부스트이며, 이들 모델 예측 결과를 합한 데이터 세트로 학습/ 예측하는 최종 모델은 로지스틱 회귀입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 ML 모델 생성\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
    "lr_clf = LogisticRegression(C=10)\n",
    "\n",
    "# 개별 모델들을 학습.\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 모델의 예측 데이터 세트를 반환하고 각 모델의 예측 정확도를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.9211\n",
      "정확도:0.9649\n",
      "정확도:0.9123\n",
      "정확도:0.9561\n"
     ]
    }
   ],
   "source": [
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 세트를 생성하고 개별 모델의 정확도 측정.\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "clf_model = [knn_pred,rf_pred,dt_pred,ada_pred]\n",
    "for model in clf_model:\n",
    "    print('정확도:{0:.4f}'.format(accuracy_score(y_test, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 알고리즘으로부터 예측된 예측값을 칼럼 레벨로 옆으로 붙여서 피처 값으로 만들어, 최종 메타 모델인 로지스틱 회귀에서 학습 데이터로 다시 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred,rf_pred,dt_pred,ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 칼럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦.\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 예측 데이터로 생성된 데이터 세트를 기반으로 최종 메타 모델인 로지스틱 회귀를 학습하고 예측 정확도를 측정하겟습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9649\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(pred, y_test)\n",
    "final = lr_clf.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test,final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 모델의 예측 데이터를 스태킹으로 재구성해 최종 메타 모델에서 학습하고 예측한 결과, 정확도가 97.37%로 개별 모델 정확도보다 향상되었습니다.( 물론 스태킹 모델로 예측한다고 무조건 개별 모델보다 좋아진다는 보장은 없습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV 세트 기반의 스태킹\n",
    "\n",
    "CV 세트 기반의 스태킹 모델은 과적합을 개선하기 위해 최종 메타 모델을 위한 데이터 세트를 만들 때 교차 검증 기반으로 예측된 결과 데이터 세트를 이용합니다.  \n",
    "앞 예제에서는 마지막에 메타 모델인 로지스틱 회귀 모델 기반에서 최종 학습할 때 레이블 데이터 세트로 학습 데이터가 아닌 테스트용 레이블 데이터 세트를 기반으로 학습했기 때문에 과적합 문제가 바랭할 수 있습니다.  \n",
    "\n",
    "CV세트 기반의 스태킹은 이에 대해 개선을 위해 모델들이 각각 교차 검증으로 메타 모델을 위한 학습용 스태킹 데이터 서ㅐㅇ성과 예측을 위한 테스트용 스태킹 데이터를 생성한 뒤 이를 기반을 메타 모델이 학습과 예측을 수행합니다.  \n",
    "\n",
    "+ 스탭1: 각 모델별로 원본 학습/테스트 데이터를 예측한 결과 값을 기반으로 메타 모델을 위한 학습용/테스트용 데이터를 생성합니다.\n",
    "+ 스탭2: 스탭 1에서 개별 모델들이 생성한 학습용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 학습할 최종 학습용 데이터 세트를 생성합니다. 마찬가지로 각 모델들이 생성한 테스트용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 예측할 최종 테스트 데이터 세트를 생성합니다. 메타 모델은 __최종적으로 생성된 학습 데이터세트와 원본 학습 데이터의 레이블 데이터를 기반으로 학습한 뒤, 최종적으로 생성된 테스트 데이터 세트를 예측하고, 원본 테스트 데이터의 레이블 데이터를 기반으로 평가합니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수.\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    # 지정된 n_folds 값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    # 추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0],1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__,'model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n",
    "        print('/t 폴드 세트', folder_counter, '시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장.\n",
    "        test_pred[:,folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean =  np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 여러 개의 분류 모델별로 stack_base_model() 함수를 수행합니다.  \n",
    "개별 모델은 앞의 기본 스태킹 모델에서 생성한 KNN, 랜덤 포레스트, 결정트리, 에이다부스트 모델활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier model 시작\n",
      "/t 폴드 세트 0 시작\n",
      "/t 폴드 세트 1 시작\n",
      "/t 폴드 세트 2 시작\n",
      "/t 폴드 세트 3 시작\n",
      "/t 폴드 세트 4 시작\n",
      "/t 폴드 세트 5 시작\n",
      "/t 폴드 세트 6 시작\n",
      "RandomForestClassifier model 시작\n",
      "/t 폴드 세트 0 시작\n",
      "/t 폴드 세트 1 시작\n",
      "/t 폴드 세트 2 시작\n",
      "/t 폴드 세트 3 시작\n",
      "/t 폴드 세트 4 시작\n",
      "/t 폴드 세트 5 시작\n",
      "/t 폴드 세트 6 시작\n",
      "DecisionTreeClassifier model 시작\n",
      "/t 폴드 세트 0 시작\n",
      "/t 폴드 세트 1 시작\n",
      "/t 폴드 세트 2 시작\n",
      "/t 폴드 세트 3 시작\n",
      "/t 폴드 세트 4 시작\n",
      "/t 폴드 세트 5 시작\n",
      "/t 폴드 세트 6 시작\n",
      "AdaBoostClassifier model 시작\n",
      "/t 폴드 세트 0 시작\n",
      "/t 폴드 세트 1 시작\n",
      "/t 폴드 세트 2 시작\n",
      "/t 폴드 세트 3 시작\n",
      "/t 폴드 세트 4 시작\n",
      "/t 폴드 세트 5 시작\n",
      "/t 폴드 세트 6 시작\n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스텝 2를 구현해 보겠습니다. 앞의 예제에서 get_stacking_base_datasets() 호출로 반환된 각 모델별 학습 데이터와 테스트 데이터를 합치기만 하면 됩니다. 넘파아의 concatenate()를 이용해 쉽게 이와 같은 기능을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 Shpae: (455, 4) 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train,rf_train,dt_train,ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test,rf_test,dt_test,ada_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape,'원본 테스트 피처 shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shpae:',Stack_final_X_train.shape, '스태킹 테스트 피처 데이터 Shape:', Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 만들어진 Stack_final_X_train은 메타 모델이 학습할 학습용 피처 데이터 세트입니다. 그리고 Stack_final_X_test는 메타 모델이 예측할 테스트용 피처 데이터 세트입니다. 스태킹 학습 피처 데이터는 원본 학습 피처 데이터와 로우(Row) 크기는 같으며, 4개의 개별 모델 예측값을 합친 것이므로 칼럼(column) 크기는 4입니다.  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_clf.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test,stack_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 메타 모델의 예측 정확도는 약 97.37%로 측정됐습니다. 지금까지의 예제에서는 개별 모델의 알고리즘에서 파라미터 튜닝을 최적으로 하지 않았지만, 스태킹을 이루는 모델은 최적으로 파라미터를 튜닝한 상태에서 스태킹 모델을 만드는 것이 일반적입니다. 여러 명으로 이뤄진 분석 팀에서 개별적으로 각각 모델을 최적으로 학습시켜서 스태킹 모델을 더 빠르게 최적화할 수 있을 것입니다. 일반적으로 스태킹 모델의 파라미터 튜닝은 개별 알고리즘 모델의 파라미터를 최적으로 튜닝하는 것을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리\n",
    "\n",
    "대부분의 앙상블 기법은 결정 트리 기반의 다수의 약한 학습기(Weak Learner)를 겹학해 변동성을 줄여 예측 오류를 줄이고 성능을 개선하고 있습니다. 결정 트리 알고리즘은 정보의 균일도에 기반한 규칙 츠리를 만들어서 예측을 수행합니다. __결정 트리는 다른 알고리즘에비해 비교적 직관적이어서 어떻게 예측 겨로가가 도출되었는지 그 과정을  쉽게 알 수 있습니다. 결정 트리의 단점으로는 균일한 최종 예측 결과를 도출하기 위해 결정 트리가 깊어지고 복잡해 지며서 과적합이 쉡게 발생하는 것입니다.__  \n",
    "  \n",
    "**앙상블 기법은** 대표적으로 배깅과 부스팅으로 구분될 수 있으며, 배깅 방식은 학습 데이터를 중복을 허용하면서 다수의 세트로 샘플링하여 이를 다수의 약한 학습기가 학습한 뒤 최종 결과를 결합해 예측하는 방식입니다. 대표적인 배깅 방식은 랜덤 포레스트는 수행 시간이 빠르고 비교적 안정적인 예측 성능을 제공하는 훌륭한 머신러닝 알고리즘 입니다.  \n",
    "\n",
    "현대의 앙상블 기법은 배깅보다는 부스팅이 더 주류를 이루고 있습니다. 부스팅은 학습기들이 순차적으로 학습을 진행하면서 예측이 틀린 데이터에 대해서는 가중치를 부여해 다음번 학습기가 학습할 때에는 이전에 예측이 틀린 데이터에 대해서는 보다 높은 정확도로 예측할 수 있도록 해줍니다. 부스팅의 효시걱인 GBM(Gradient Boosting Machine)은 뛰어난 예측 성능을 가졌지만, 수행 시간이 너무 오래 걸린다는 단점이 있습니다.\n",
    "\n",
    "XGBoost와 LightGBM은 현대 가장 각광 받고 있는 부스팅 기반 머신러냉 패키지입니다. 속도향상 과적합 문제를 향상시킨 패키지 모델입니다.\n",
    "\n",
    "스태킹 모델은 여러 개의 개별 모델들이 생성한 예측 데이터를 기반으로 최종 메타 모델이 학습할 별도의 학습 데이터 세트와 예측할 테스트 데이터 세트를 재 생성하는 기법입니다. 스태킹 모델의 핵슴은 바로 메타 모델이 사용할 학습 데이터 세트와 예측 데이터 세트를 개별 모델의 예측값들을 스태킹 형태로 결합해 생성하는 데 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
