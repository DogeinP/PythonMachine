{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가\n",
    "    \n",
    "    머신러닝은 데이터 가공/변환, 모델 학습/예측, 그리고 평가(Evaluation)의 프로세스로 구성됩니다.\n",
    "    회귀위 평가는 실제 값과 예측값의 오차 평균값에 기반, \n",
    "    분류의 평가 방법은 정확도(Accuracy), 오차 행렬(Confusion Matrix), 정밀도(Precision), 재현율(Recall), F1스코어, ROC AUC\n",
    "    분류는 클래스 값 종류에 따라 이진 분류, 멀티 분류로 나뉠 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도\n",
    "    \n",
    "    정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.\n",
    "    정확도(Accuracy) = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "    정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표입니다. 하지만 이진분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도수치 하나만 가지고 성능을 평가하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 예제에서는 사이킷런의 BaseEstimator 클래스를 상속받아 아무런 학습을 하지 않고, 성별에 따라 생존자를 예측하는 단순한 Classifier를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit() 메서드는 아무것도 학습하지 않음.\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict() 메서드는 단순히 Sex 피러가 1이면 0, 그렇지 않으면 1로 예측함.\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0],1))\n",
    "        for i in range (X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2장 예제중 일부\n",
    "# Null 처리 함수\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는:0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할.\n",
    "titanic_df = pd.read_csv('./train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행.\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는:{0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    이렇게 단순한 알고리즈므으로 예측을 하더라도 데이터의 구성에 따라 정확도 결과는  약 78.7%로 꽤 높은 수치가 나올 수 있기에 정확도를 평가 지표로 사용할 때는 매우 신중해야 합니다.\n",
    "    특히 정확도는 불균형한(imbalanced) 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 평가 지표가 아닙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불균형 데이터를 활용해 모든 데이터를 False로, 즉 0으로 예측하는 classifier를 이용해 정확도를 측정하면 약 90%에 가까운 예측 정확도를 나타냅니다.\n",
    "\n",
    "아무것도 하지 않고 무조건 특정한 결과를 찍어도 데이터 분포도가 균일하지 않은 경우 높은 수치가 나타날 수 있는 것이 정확도 평가 지표의 맹정 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "    \n",
    "# 사이킷런의 내장 데이터 세트인 load_digits() 이용해 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "# digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환.\n",
    "y = (digits.target ==7 ).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불균형 데이터로 생성한 y_test의 데이터 분포도를 확인하고 MyFakeClassifier를 이용해 예측과 평가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기: (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인.\n",
    "print('레이블 테스트 세트 크기:',y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    단순히 predict()의 결과를 np.zeros()로 모든 0값으로 반환함에도 불구하고 450개의 테스트 데이터 세트에 수행한 예측 정확도는 90%입니다. 단지 모든 것을 0으로만 예측해도 정확도가 90%로 유수의 ML 알고리즘과 어깨를 겨룰 수 있다는 것은 말도 안되는 결과입니다.\n",
    "    \n",
    "    이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용돼서는 안 됩니다.\n",
    "    정확도가 가지는 분류평가 지표로서 이러한 한계점을 극복하기 위해 여러 가지 분류 지표와 함께 적용해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차 행렬\n",
    "\n",
    "    이진 분류에서 성능 지표로 잘 활용되는 오차행렬(Confusion matrix, 혼동행렬)은 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고(Confused)있는지도 함께 보여주는 지표입니다. 즉. 이진 분류의 예측 오류가 얼마인지와 어떤한 유형의 예측 오류가 발생하고 있는지를 함께 나타냅니다.\n",
    "    \n",
    "    오차 행렬은 다음과 같은 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매핑되는지를 나타냅니다.\n",
    "    TN : 예측값을 Negative 값 0으로 예측했고 실제 값 역시 Negative 값 0\n",
    "    FP : 예측값을 Positive 값 1으로 예측했고 실제 값은 Negative 값 0\n",
    "    FN : 예측값을 Negative 값 0으로 예측했는데 실제 값은 Positive 값 1\n",
    "    TP : 예측값을 Positive 값 1로 예측했는데 실제 값 역시 Positive 값 1\n",
    "    \n",
    "    사이킷런은 오차 행렬을 구하기 위해 confusion_matrix() API를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    출력된 오차 행렬은 ndarray 형태 입니다.TN은 array[0,0]로 405개 FN은 array [1,0]으로 45개로 7이 아닌 digit을 7로 판단한 경우\n",
    "    이처럼 오차행렬을 이용하여 Classifier의 성늘을 측정할 수 있는 주요 지표인 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있습니다.\n",
    "    불균형한 데이터 세트에서 정확도보다 더 선호되는 평가 지표인 정밀도(Precision)와 재현율(Recall)에 대한 지표가 중요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정밀도와 재현율\n",
    "\n",
    "    정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초정을 맞춘 평가 지표입니다.\n",
    "    \n",
    "    정밀도(Precision) = TP / (FP + TP)\n",
    "    재현율(Recall) = TP / (FN + TP)\n",
    "    \n",
    "    정밀도는 예측은 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일차한 데이터의 비율을 뜻합니다. Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 불립니다.\n",
    "    \n",
    "    재현율은 실제 값이 Positive인 대상중에 예측과 실제값이 Positive로 일차한 데이터의 비율을 뜻합니다.\n",
    "    \n",
    "    정밀도와 재현율은 이진 분류 모델의 업무 특성에 따라서 특정 평가지표가 더 중요한 지표로 간주될 수 있습니다.\n",
    "    재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우입니다. 예를 들어 암 판단 모델은 재현율이 훨씬 중요한 지표입니다. 왜냐하면 실제 Positive인 암 환자를 Negative 음성으로 잘못 판단 했을 경우 오류의 대가가 생명을 앗아갈 정도로 심각하기 때문입니다. 보험사기와 같은 금융 사기 적발 모델도 재현율이 중요합니다.\n",
    "    \n",
    "    보통은 재현율이 정밀도보다 상대적으로 중요한 업무가 많지만, 정밀도가 더 중요한 지표인 경우는 스팸메일 여부를 판단하는 모델의 경우 실제 Positive인 스펨메일을 Negative인 일반 메일로 분류하더라도 사용자가 불편함을 느끼는 정도지만, 반대일 경우 스펨 메일로 분류할 경우에는 메일을 아예 받지 못학 ㅔ돼 업무에 차질이 생깁니다.\n",
    "    \n",
    "    재현율 정밀도 모두 TP를 높이는 데 동일하게 초점을 맞추지만, 재현율은 FN(실제 Positive, 예측 Negative)를 낮추는데, 정밀도는 FP를 낮추는 데 초점을 맞춥니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:.4f}, 정밀도:{1:.4f}, 재현율:{2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도:0.8659, 정밀도:0.8246, 재현율:0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doo11\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('./train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    정밀도(Precision)에 비해 재현율(Recall)이 낮게 나왔습니다. 재현율 또는 정밀도를 좀 더 강화할 방법은 무엇일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도/재현율 트레이드오프\n",
    "\n",
    "    분류하려는 업무의 특성상 정밀도 또는 재현율이 특별히 강조돼야 할 경우 분류의 결정 임계값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다. 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치는  떨어지기 쉽습니다. 이를 정밀도/재현율의 트레이드오프(Trade-off)라고 합니다.\n",
    "    \n",
    "    사이킷런의 분류 알고리즘은 개별 레이블별로 결정 확률을 구합니다. 예측 확률이 큰 레이블 값으로 예측하게하며, 0이 될 확률이 10%, 1이 될 확률이 90%일 경우 최종 예측은 더 큰 확률을 가진 1로 예측합니다. 일반적으로 이진 분류에서의 임계값을 0.5로 정하고 이 값보다 확률이 크면 Positive, 작으면 Negative로 결정합니다.\n",
    "    \n",
    "    사이킷런은 개별 데이터별로 예측 확률을 반환하는 메서드인 predict_proba()를 제공합니다. 피처 레코드의 개별 클래스값이 아닌 예측 확률 결과를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape:(179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출\n",
      ": [[0.44935228 0.55064772]\n",
      " [0.86335513 0.13664487]\n",
      " [0.86429645 0.13570355]]\n",
      "두 개의 class중에서 더 큰 확률을 클래스 값으로 예측\n",
      " [[0.44935228 0.55064772 1.        ]\n",
      " [0.86335513 0.13664487 0.        ]\n",
      " [0.86429645 0.13570355 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape:{0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출\\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결과값 array를 병합(concatenate)해 예측 확률과 결괏값을 하눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)],axis=1)\n",
    "print('두 개의 class중에서 더 큰 확률을 클래스 값으로 예측\\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    반환 결과인 ndarray는 0과 1에 대한 확률을 나타내므로 첫 번째 칼럼과 두 번째 칼럼 값을 더하면 1이 됩니다.\n",
    "    predict() 메서드는 predict_proba() 메서드에 기반해 생성된 API입니다.\n",
    "    사이킷런이 어떻게 정밀도/재현율 트레이드 오프를 구현했는지를 이해하는 데 도움을 줍니다.\n",
    "    임계값을 조절해 정밀도와 재현율의 성능 수치를 상호 보완적으로 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold 변수를 특정 값으로 설정하고 Binarizer 클래스를 객체로 생성합니다.\n",
    "\n",
    "입력받은 ndarray를 지정된 threshold보다 같거나 작으면 0,1 값으로 변환해 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1,-1,2],\n",
    "    [2,0,0],\n",
    "    [0,1.1,1.2]]\n",
    "\n",
    "# X의 개별 원소들이 threshold 값보다 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    입력된 X 데이터 세트에서 threshold 값에 따라 변환된 0,1 값을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 Binarizer를 이용해 사이킷런 predict()의 의사(pseudo) 코드를 만들어 보겠습니다.\n",
    "\n",
    "바로 앞 예제의 LogisticRegression 객체의 predict_proba() 메서드로 구한 각 클래스별 예측 확률값인 pred_proba 객체 변수에 분류 결정 임계값(threshold)을 0.5로 지정한 Binarizer 클래스를 적용해 최종 값을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도:0.8659, 정밀도:0.8246, 재현율:0.7705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer 의 threshold 설정값. 분류 결정 임계값임.\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환 값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
